<!DOCTYPE html>
<html lang="en">
  <head>
    <title>EVA-Gaussian</title>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Projectpage of GPS-Gaussian</title>
    <!-- Bootstrap -->
    <link href="assets/EVA-Gaussian/css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>EVA-Gaussian: 3D Gaussian-Based Real-time
              Human Novel View Synthesis Under Diverse
              Camera Settings</h2>
            <!-- <h4 style="color:#5a6268;">CVPR 2024 Highlight</h4> -->
            <hr>
            <h6> 
              Anonymous
              <!-- <a href="https://shunyuanzheng.github.io" target="_blank">Shunyuan Zheng<sup>&dagger;,1</sup></a>,
                <a href="https://yaourtb.github.io" target="_blank">Boyao Zhou<sup>2</sup></a>,
                <a href="https://dsaurus.github.io/saurus" target="_blank">Ruizhi Shao<sup>2</sup></a>,
                <a href="https://liuboning2.github.io" target="_blank">Boning Liu<sup>2</sup></a>,
                <a href="http://homepage.hit.edu.cn/zhangshengping" target="_blank">Shengping Zhang<sup>&#x2709,1,3</sup></a>,
                <a href="https://liqiangnie.github.io" target="_blank">Liqiang Nie<sup>1</sup></a>,
                <a href="https://liuyebin.com" target="_blank">Yebin Liu<sup>2</sup></a></h6> -->
            <!-- <p>Hongkong University of Science and Technology</p> -->
            <!-- <p>*Corresponding author</p> -->
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://anonymousiclr2025.github.io/iclr2025/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://anonymousiclr2025.github.io/iclr2025/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-youtube"></i> Video</a></p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://anonymousiclr2025.github.io/iclr2025/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code</a></p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
<!--             <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="assets/motivation.mp4" type="video/mp4">
            </video> -->
            <!-- <iframe src="assets/EVA-Gaussian/images/visualization.pdf" style="width:100%; height:600px;"></iframe> -->
            <img src="assets/EVA-Gaussian/images/visualization-1.png" width="90%" alt=""/>
              <!-- <br><br> -->
          <p class="text-left">We propose a three-stage pipeline named EVA-Gaussian for 3D human novel view synthesis across diverse camera settings. Specifically, we first introduce an Efficient cross-View Attention (EVA) module to accurately estimate the position of each 3D Gaussian from the source images. Then, we integrate the source images with the estimated Gaussian position map to predict the attributes and feature embeddings of the 3D Gaussians. Finally, we employ a recurrent feature refiner to correct artifacts caused by geometric errors in position estimation and enhance visual fidelity. To further improve synthesis quality, we incorporate a powerful anchor loss function for both 3D Gaussian attributes and human face landmarks. Experimental results on the THuman2.0 and THumansit datasets showcase the superiority of our EVA-Gaussian approach in rendering quality across diverse camera settings.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- <section>
    <div class="video">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
              <video width="50%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/video_diff_degree.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- <section>
    <div class="video">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
           <video width="50%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/vis_6cams_video.mp4" type="video/mp4">
            </video>
            <video width="50%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/vis_5cams_video.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->
  <section>
    <div class="video">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Video</h3>
          <hr style="margin-top:0px">
          <div style="display: flex; justify-content: center;">
            <video width="50%" playsinline="" autoplay="" loop="" preload="" muted="" controls>
              <source src="assets/EVA-Gaussian/videos/EVA-Gaussian.mp4" type="video/mp4">
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="video">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
          <hr style="margin-top:0px">
          <div style="display: flex; justify-content: center;">
            <video width="40%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/vis_6cams_video.mp4" type="video/mp4">
            </video>
            <video width="40%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/vis_5cams_video.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>
  
  <!-- <section>
    <div class="video">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
           <video width="50%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/video.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Live Demo</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Live demo for handling challenging hairstyles, human-object interaction and multi-person scenario</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/wcy_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/jds_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/zby_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/multi_live.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method Overview</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/network_structure-1.png" width="80%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              <b><strong> Overview of EVA-Gaussian</strong></b>. EVA-Gaussian takes sparse-view images captured around a human subject as input and performs three key stages: (1) estimating the positions of 3D Gaussians, (2) inferring the remaining attributes (i.e., opacities, scales, quaternions, and features) of these Gaussians, and (3) refining the output image in a recurrent manner
            </p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>EVA Module</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/EVA_module-1.png" width="60%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              <b><strong>Efficient cross-View Attention (EVA)</strong></b> module for 3D Gaussian position estimation. EVA takes multi-view image features as input, embeds them into window patches using a shifted algorithm, and performs cross-view attention between the features from different views.
            </p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>Regularization Loss</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/face_landmark-1.png" width="80%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              Attribute regularization. We regularize the opacities and scales of Gaussians, as well as the position mismatches among the Gaussians in the landmark collection. The optimization of position mismatch when it falls below a specific tolerance.</p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>Visualization</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/main_vis-1.png" width="100%" alt=""/>
            <p>&nbsp;</p>
            <!-- <h4>Reconstruct under Various Input</h4> -->
            <!-- <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/video_diff_degree.mp4" type="video/mp4">
            </video> -->
          </div>
          <!-- <div class="col-12 text-center">
            <h3></h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/table_ffw-1.png" width="60%" alt=""/>
            <p class="text-left"></p>
              More Comparision with Feed-Forward Methods
            </p>
            <p>&nbsp;</p> -->
          </div>
      </div>
    </div>
  </section>
  <br>

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Demo Video</h3>
            <hr style="margin-top:0px">
            If the video does not play, please click <a href="assets/EVA-Gaussian/videos/youtube_video.mp4" target="_blank">here</a> to watch it.
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/HjnBAqjGIAo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>
  <!-- @inproceedings{zheng2024gpsgaussian,
  title={GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis},
  author={Zheng, Shunyuan and Zhou, Boyao and Shao, Ruizhi and Liu, Boning and Zhang, Shengping and Nie, Liqiang and Liu, Yebin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}} -->
</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>