<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Projectpage of GPS-Gaussian</title>
    <!-- Bootstrap -->
    <link href="assets/EVA-Gaussian/css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>EVA-Gaussian: 3D Gaussian-Based Real-time
              Human Novel View Synthesis Under Arbitrary
              Camera Settings</h2>
            <!-- <h4 style="color:#5a6268;">CVPR 2024 Highlight</h4> -->
            <hr>
            <h6> 
              Anonymous
              <!-- <a href="https://shunyuanzheng.github.io" target="_blank">Shunyuan Zheng<sup>&dagger;,1</sup></a>,
                <a href="https://yaourtb.github.io" target="_blank">Boyao Zhou<sup>2</sup></a>,
                <a href="https://dsaurus.github.io/saurus" target="_blank">Ruizhi Shao<sup>2</sup></a>,
                <a href="https://liuboning2.github.io" target="_blank">Boning Liu<sup>2</sup></a>,
                <a href="http://homepage.hit.edu.cn/zhangshengping" target="_blank">Shengping Zhang<sup>&#x2709,1,3</sup></a>,
                <a href="https://liqiangnie.github.io" target="_blank">Liqiang Nie<sup>1</sup></a>,
                <a href="https://liuyebin.com" target="_blank">Yebin Liu<sup>2</sup></a></h6> -->
            <p>Hongkong University of Science and Technology</p>
            <!-- <p>*Corresponding author</p> -->
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://zhenliuzju.github.io/huyingdong/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://zhenliuzju.github.io/huyingdong/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-youtube"></i> Video</a></p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://zhenliuzju.github.io/huyingdong/EVA-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code</a></p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
<!--             <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="assets/motivation.mp4" type="video/mp4">
            </video> -->
            <!-- <iframe src="assets/EVA-Gaussian/images/visualization.pdf" style="width:100%; height:600px;"></iframe> -->
            <img src="assets/EVA-Gaussian/images/visualization-1.png" width="90%" alt=""/>
              <!-- <br><br> -->
          <p class="text-left"> We introduce a three-stage pipeline named EVA-Gaussian for 3D human novel view synthesis across arbitrary camera settings. In the Gaussian Position Estimation stage, the position of each 3D Gaussian is estimated leveraging an Efficient cross-View Attention (EVA) module. In the Gaussian Attributes Estimation stage, the RGB image and Gaussian position map are combined for predicting 3D Gaussian attributes and feature embedding. Finally, in the Feature Refinement stage, a recurrent feature refiner is employed to address geometrical errors and enhance visual quality. Additionally, powerful regularization loss functions are incorporated for 3D Gaussian attributes and human face landmarks to enhance visual quality.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Data collected by ourselves</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/zsy_freeview.mp4" type="video/mp4">
            </video>
          <h6 style="color:#8899a5"> Data from <a href="https://dna-rendering.github.io/" target="_blank">DNA-Rendering</a></h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/dna173_freeview.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/dna188_freeview.mp4" type="video/mp4">
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Live Demo</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Live demo for handling challenging hairstyles, human-object interaction and multi-person scenario</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/wcy_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/jds_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/zby_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/EVA-Gaussian/videos/multi_live.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method Overview</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/network_structure-1.png" width="80%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              <b>Overview of EVA-Gaussian.</b> Given arbitrary sparse view images as input from surrounding of a human, EVA-Gaussian takes three stages correspondingly to estimate Gaussian position, inference Gaussian features, and finally refine the image in a recurrent manner.
            </p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>EVA Module</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/EVA_module-1.png" width="60%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              Efficient cross-View Attention (EVA) module for 3D Gaussian position estimation. EVA takes multi-view image features as input, embeds them into window patches in a shifted algorithm, and at last performs cross attention for each feature. When multiple views are intended to be inferenced, we average query and key over all of the inference features using linear layers.
            </p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>Regularization Loss</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/face_landmark-1.png" width="80%" alt=""/>
            <p>&nbsp;</p>
            <p class="text-left">
              We further propose regularization terms to enhance the human face reconstruction quality. Specifically, the proposed loss function regularizes Gaussian scales and opacity to guarantee them to be close to each other, and matches Gaussians that come from different views to force their locations to the same landmark. 
            </p>
            <p>&nbsp;</p>
          </div>
          <div class="col-12 text-center">
            <h3>Visualization</h3>
              <hr style="margin-top:0px">
            <img src="assets/EVA-Gaussian/images/main_vis-1.png" width="100%" alt=""/>
            <p>&nbsp;</p>
          </div>
      </div>
    </div>
  </section>
  <br>

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Demo Video</h3>
            <hr style="margin-top:0px">
            If the video does not play, please click <a href="assets/EVA-Gaussian/videos/youtube_video.mp4" target="_blank">here</a> to watch it.
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/HjnBAqjGIAo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>
  <!-- @inproceedings{zheng2024gpsgaussian,
  title={GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis},
  author={Zheng, Shunyuan and Zhou, Boyao and Shao, Ruizhi and Liu, Boning and Zhang, Shengping and Nie, Liqiang and Liu, Yebin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}} -->
</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>